{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# main_path = './drive/MyDrive/NewsGeneration-NLP-Teknofest'\n",
    "main_path = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../Preprocess-Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from category_reducer import category_reducer\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow import expand_dims\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2, mobilenet_v2\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, concatenate\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Title                100 non-null    object\n",
      " 1   Content              100 non-null    object\n",
      " 2   Content_url          100 non-null    object\n",
      " 3   News_type            100 non-null    object\n",
      " 4   Day_month_year_hour  100 non-null    object\n",
      " 5   Img_url              100 non-null    object\n",
      " 6   img_path             100 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 5.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    # Load the data from the csv file and reduce the number of categories\n",
    "    '''\n",
    "    data_path = main_path + \"/Data/news-data-with-imgs.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    df = data.copy()\n",
    "\n",
    "    # Reducing the number of categories\n",
    "    df = category_reducer(df)\n",
    "\n",
    "    print(df.info())\n",
    "\n",
    "    df = df[['Content', 'Title', 'img_path']]\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "# df = df.iloc[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Title                100 non-null    object\n",
      " 1   Content              100 non-null    object\n",
      " 2   Content_url          100 non-null    object\n",
      " 3   News_type            100 non-null    object\n",
      " 4   Day_month_year_hour  100 non-null    object\n",
      " 5   Img_url              100 non-null    object\n",
      " 6   img_path             100 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 5.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = load_data()\n",
    "\n",
    "df = df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessImg:\n",
    "    '''\n",
    "    # Class to preprocess the images and get the size information of the images.\n",
    "    '''\n",
    "    def __init__(self, images_path):\n",
    "        self.images_path = images_path\n",
    "        self.loaded_imgs = []\n",
    "        self.img_arrays = []\n",
    "\n",
    "    def load_img(self, target_size):\n",
    "        for img in os.listdir(self.images_path):\n",
    "            img = load_img(os.path.join(self.images_path, img), target_size=target_size)\n",
    "            self.loaded_imgs.append(img)\n",
    "\n",
    "        return self.loaded_imgs\n",
    "\n",
    "    def img_to_array(self):\n",
    "        '''\n",
    "        # Load the images from the directory\n",
    "\n",
    "        Returns:\n",
    "            - loaded_imgs: List of loaded images\n",
    "        '''\n",
    "        for img in self.loaded_imgs:\n",
    "            img = img_to_array(img)\n",
    "            self.img_arrays.append(img)\n",
    "        return np.array(self.img_arrays) / 255.0\n",
    "\n",
    "    def get_size_info(self, loaded_imgs):\n",
    "        '''\n",
    "        # Get the size information of the images\n",
    "\n",
    "        Args:\n",
    "            - loaded_imgs: list of loaded images\n",
    "\n",
    "        Returns:\n",
    "            - weights_mean: Mean of the weights of the images\n",
    "            - weights_std: Standard deviation of the weights of the images\n",
    "            - heights_mean: Mean of the heights of the images\n",
    "            - heights_std: Standard deviation of the heights of the images\n",
    "        '''\n",
    "        img_weights = []\n",
    "        img_heights = []\n",
    "        for size in loaded_imgs:\n",
    "            img_weights.append(size.size[0])\n",
    "            img_heights.append(size.size[1])\n",
    "\n",
    "        weights_mean = np.mean(img_weights)\n",
    "        weights_std = np.std(img_weights)\n",
    "\n",
    "        heights_mean = np.mean(img_heights)\n",
    "        heights_std = np.std(img_heights)\n",
    "\n",
    "        return weights_mean, weights_std, heights_mean, heights_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean width: 224.0\n",
      "Standard deviation of widths: 0.0\n",
      "Mean height: 224.0\n",
      "Standard deviation of heights: 0.0\n",
      "==\n",
      "Image shapes:  (100, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "img_preprocessor = PreprocessImg(main_path + \"/Data/imgs/\")\n",
    "\n",
    "loaded_imgs = img_preprocessor.load_img(target_size=(224, 224))\n",
    "image_data = img_preprocessor.img_to_array()\n",
    "\n",
    "widths_mean, widths_std, heights_mean, heights_std = img_preprocessor.get_size_info(loaded_imgs)\n",
    "\n",
    "print(\"Mean width:\", widths_mean)\n",
    "print(\"Standard deviation of widths:\", widths_std)\n",
    "print(\"Mean height:\", heights_mean)\n",
    "print(\"Standard deviation of heights:\", heights_std)\n",
    "print(\"==\")\n",
    "print('Image shapes: ', image_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessText(Tokenizer):\n",
    "    '''\n",
    "    # Class to tokenize and pad the text data\n",
    "\n",
    "    Args:\n",
    "        - data: The text data list or series to be tokenized and padded\n",
    "    '''\n",
    "    def __init__(self, data):\n",
    "        super().__init__(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "        self.start_mark = '<start> '\n",
    "        self.end_mark = ' <end>'\n",
    "\n",
    "        data = data.apply(lambda x: self.start_mark + x + self.end_mark)\n",
    "\n",
    "        self.fit_on_texts(data)\n",
    "        self.tokens = self.texts_to_sequences(data)\n",
    "\n",
    "        self.numbers_of_words = [len(token) for token in self.tokens]\n",
    "        self.max_tokens = max(self.numbers_of_words)\n",
    "\n",
    "        self.padded_tokens = pad_sequences(self.tokens, padding='post', truncating='post')\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    # re-padding the tokens\n",
    "    def re_pad(self, max_tokens=None):\n",
    "        '''\n",
    "        # Re-pad the tokens to a new maximum length\n",
    "\n",
    "        Args:\n",
    "            - max_tokens: The new maximum lenght of the tokens\n",
    "        '''\n",
    "\n",
    "        self.padded_tokens = pad_sequences(self.tokens, maxlen=max_tokens, padding='post', truncating='post')\n",
    "        return self.padded_tokens\n",
    "    def get_info(self):\n",
    "        '''\n",
    "        # Get the information about the tokenized and padded data\n",
    "        '''\n",
    "        print(\"Max tokens: \", self.max_tokens)\n",
    "        print(\"Mean tokens: \", int(np.mean(self.numbers_of_words)))\n",
    "        print(\"Standard deviation of tokens: \", int(np.std(self.numbers_of_words)))\n",
    "        print(\"Vocabulary Size: \", len(self.word_index) +1 )\n",
    "        print('Shape of padded tokens: ', self.padded_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokens:  11\n",
      "Mean tokens:  9\n",
      "Standard deviation of tokens:  1\n",
      "Vocabulary Size:  40\n",
      "Shape of padded tokens:  (5, 11)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreprocessText(df['Title'])\n",
    "\n",
    "padded_tokens = tokenizer.padded_tokens\n",
    "max_tokens = tokenizer.max_tokens\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "start_token = tokenizer.word_index[tokenizer.start_mark.strip()]\n",
    "end_token = tokenizer.word_index[tokenizer.end_mark.strip()]\n",
    "\n",
    "tokenizer.get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images, X_texts, y_texts = [], [], []\n",
    "for img, seq in zip(image_data, padded_tokens):\n",
    "    for i in range(1, len(seq)):\n",
    "        in_seq, out_seq = seq[:i], seq[i]\n",
    "        in_seq = pad_sequences([in_seq], maxlen=max_tokens)[0]\n",
    "        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "        X_images.append(img)\n",
    "        X_texts.append(in_seq)\n",
    "        y_texts.append(out_seq)\n",
    "\n",
    "X_images, X_texts, y_texts = np.array(X_images), np.array(X_texts), np.array(y_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " mobilenetv2_1.00_224 (Function  (None, 7, 7, 1280)  2257984     ['input_5[0][0]']                \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 1280)        0           ['mobilenetv2_1.00_224[0][0]']   \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          327936      ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 300)    12000       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           8224        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 256)          570368      ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 288)          0           ['dense_4[0][0]',                \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 40)           11560       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,188,072\n",
      "Trainable params: 930,088\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "x = base_model(image_input)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "image_embedding = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Decoder\n",
    "text_input = Input(shape=(None,))\n",
    "text_embedding = Embedding(vocab_size, 300)(text_input)\n",
    "text_lstm = LSTM(256)(text_embedding)\n",
    "\n",
    "combined = concatenate([image_embedding, text_lstm])\n",
    "output = Dense(vocab_size, activation='softmax')(combined)\n",
    "\n",
    "model = Model(inputs=[image_input, text_input], outputs=output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
